{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bJGLUbHTaMsf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn import datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rCTMe4mRbyIO"
      },
      "outputs": [],
      "source": [
        "#Input data\n",
        "dataset = pd.read_csv('Dataset/HeartDisease.csv')\n",
        "dataset = np.array(dataset)\n",
        "np.random.shuffle(dataset)\n",
        "dataset_train = dataset[: 46000, :]\n",
        "dataset_valid = dataset[46000 : 51000, :]\n",
        "dataset_test = dataset[51000:, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Customize dataset\n",
        "class HeartDataset(Dataset):\n",
        "  def __init__(self, indata):\n",
        "    dataset = indata\n",
        "    dataset = np.array(dataset)\n",
        "    self.x = dataset[:, 1:]\n",
        "    self.y = dataset[:, 0]\n",
        "    self.n_samples = self.x.shape[0]\n",
        "    self.n_feature = self.x.shape[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x[index], self.y[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcW0GfmJb6rG",
        "outputId": "019d5c48-3ee7-41e0-f651-34ff3abcc741"
      },
      "outputs": [],
      "source": [
        "#Data loading\n",
        "data_train = HeartDataset(dataset_train)\n",
        "data_valid = HeartDataset(dataset_valid)\n",
        "X_test = torch.tensor(dataset_test[:, 1:], dtype = float)\n",
        "Y_test = torch.tensor(dataset_test[:, 0], dtype = float)\n",
        "dataloader = DataLoader(dataset=data_train, batch_size=32, shuffle=True)\n",
        "validloader = DataLoader(dataset=data_valid, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "80M-hG41ayHO"
      },
      "outputs": [],
      "source": [
        "#Build Logistic Regression model\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear1 = nn.Linear(input_size, output_size)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.linear1(x.float())\n",
        "    y_pred = self.sigmoid(out)\n",
        "    return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qT9F1tIXbZ38",
        "outputId": "76be4a90-6875-46d1-9408-34a930a3cf5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 \t\t Training Loss: 16.674379199292485 \t\t Validation Loss: 0.28428218302548314\n",
            "Validation Loss Decreased(inf--->44.632303) \t Saving The Model\n",
            "Epoch 2 \t\t Training Loss: 0.24549461100302294 \t\t Validation Loss: 0.23941974778463887\n",
            "Validation Loss Decreased(44.632303--->37.588900) \t Saving The Model\n",
            "Epoch 3 \t\t Training Loss: 0.2436092740672178 \t\t Validation Loss: 0.22741949323351215\n",
            "Validation Loss Decreased(37.588900--->35.704860) \t Saving The Model\n",
            "Epoch 4 \t\t Training Loss: 0.24638660584792743 \t\t Validation Loss: 0.3185973498691467\n",
            "Epoch 5 \t\t Training Loss: 0.24387199678412938 \t\t Validation Loss: 0.24384581810160047\n",
            "Epoch 6 \t\t Training Loss: 0.24704923258669498 \t\t Validation Loss: 0.29078838646791544\n",
            "Epoch 7 \t\t Training Loss: 0.2442854783461806 \t\t Validation Loss: 0.24157941155135632\n",
            "Epoch 8 \t\t Training Loss: 0.24634683167306715 \t\t Validation Loss: 0.22878826279074524\n",
            "Epoch 9 \t\t Training Loss: 0.24671133891621058 \t\t Validation Loss: 0.2303987116950333\n",
            "Epoch 10 \t\t Training Loss: 0.24513985981752834 \t\t Validation Loss: 0.23037303016064273\n",
            "Epoch 11 \t\t Training Loss: 0.2426909775167486 \t\t Validation Loss: 0.27011596826705964\n",
            "Epoch 12 \t\t Training Loss: 0.24412230971646243 \t\t Validation Loss: 0.23244538423931524\n",
            "Epoch 13 \t\t Training Loss: 0.24342086134408503 \t\t Validation Loss: 0.22754293447656995\n",
            "Epoch 14 \t\t Training Loss: 0.2480764932764023 \t\t Validation Loss: 0.2824854484053364\n",
            "Epoch 15 \t\t Training Loss: 0.24500312132279028 \t\t Validation Loss: 0.23237562450064217\n",
            "Epoch 16 \t\t Training Loss: 0.24789434597181137 \t\t Validation Loss: 0.22948884771792752\n",
            "Epoch 17 \t\t Training Loss: 0.24279349485298254 \t\t Validation Loss: 0.24621727815858876\n",
            "Epoch 18 \t\t Training Loss: 0.24577239548796542 \t\t Validation Loss: 0.23454602971483188\n",
            "Epoch 19 \t\t Training Loss: 0.24759175850924295 \t\t Validation Loss: 0.23030403930290488\n",
            "Epoch 20 \t\t Training Loss: 0.2452850425492853 \t\t Validation Loss: 0.2327782745194283\n",
            "Epoch 21 \t\t Training Loss: 0.24203306415360498 \t\t Validation Loss: 0.25372861622933557\n",
            "Epoch 22 \t\t Training Loss: 0.2471068761070545 \t\t Validation Loss: 0.24839008799427822\n",
            "Epoch 23 \t\t Training Loss: 0.24634754971791478 \t\t Validation Loss: 0.2419532990427154\n",
            "Epoch 24 \t\t Training Loss: 0.24461049238810514 \t\t Validation Loss: 0.22892898314033344\n",
            "Epoch 25 \t\t Training Loss: 0.24482531970501548 \t\t Validation Loss: 0.24611397396037532\n",
            "Epoch 26 \t\t Training Loss: 0.2461003419879684 \t\t Validation Loss: 0.23559541502006495\n",
            "Epoch 27 \t\t Training Loss: 0.2453058118619781 \t\t Validation Loss: 0.24985294398750849\n",
            "Epoch 28 \t\t Training Loss: 0.24438515354740603 \t\t Validation Loss: 0.2662705399190924\n",
            "Epoch 29 \t\t Training Loss: 0.24474165637385467 \t\t Validation Loss: 0.23288916699161197\n",
            "Epoch 30 \t\t Training Loss: 0.24489635502808157 \t\t Validation Loss: 0.2289513646844466\n"
          ]
        }
      ],
      "source": [
        "#Train and validate model\n",
        "n_feature = data_train.n_feature\n",
        "n_samples = data_train.n_samples\n",
        "model = LogisticRegression(n_feature, 6, 1)\n",
        "loss = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "min_valid_loss = np.inf\n",
        "epochs = 30\n",
        "for epoch in range(epochs):\n",
        "    training_loss = 0\n",
        "    validating_loss = 0\n",
        "    for input, label in dataloader:\n",
        "        y_pred = model(input)\n",
        "        label = label.reshape(-1, 1).float()\n",
        "        l = loss(y_pred, label)\n",
        "        training_loss += l.item()\n",
        "        l.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    \n",
        "    for input, label in validloader:\n",
        "        y_pred = model(input)\n",
        "        label = label.reshape(-1, 1).float()\n",
        "        l = loss(y_pred, label)\n",
        "        validating_loss += l.item()\n",
        "    print(f'Epoch {epoch+1} \\t\\t Training Loss: {training_loss / len(dataloader)} \\t\\t Validation Loss: {validating_loss / len(validloader)}')\n",
        "    if min_valid_loss > validating_loss:\n",
        "        print(f'Validation Loss Decreased({min_valid_loss:.6f}--->{validating_loss:.6f}) \\t Saving The Model')\n",
        "        min_valid_loss = validating_loss\n",
        "        # Saving State Dict\n",
        "        torch.save(model.state_dict(), 'saved_model.pt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZRQGtpnf5TO",
        "outputId": "fca8b643-87e2-4966-9e85-ab40d112fd06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Accuracy 92%\n"
          ]
        }
      ],
      "source": [
        "#Model Testing\n",
        "model.load_state_dict(torch.load('saved_model.pth'))\n",
        "predictions = model(X_test).detach().numpy()\n",
        "predictions = predictions.reshape(-1).round()\n",
        "Y_train = Y_test.detach().numpy()\n",
        "result = predictions == Y_train\n",
        "print(f\"Model Accuracy {int(np.sum(result)/len(result)*100)}%\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
