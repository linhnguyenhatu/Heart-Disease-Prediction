{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1P71s2rEp6IP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GAxLyJO7p6IQ"
      },
      "outputs": [],
      "source": [
        "#Data Input\n",
        "dataset = pd.read_csv('Dataset/HeartDisease.csv')\n",
        "dataset = dataset.values\n",
        "dataset_train = dataset[:46000, :]\n",
        "dataset_test = dataset[46000:, :]\n",
        "X_train = dataset_train[:, 1:]\n",
        "Y_train = dataset_train[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rYiiIDP8p6IS"
      },
      "outputs": [],
      "source": [
        "#Node class\n",
        "class Node():\n",
        "    def __init__(self, index = None, threshold = None, left = None, right = None, info_gain = None, value = None):\n",
        "        self.index = index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        self.value = value\n",
        "\n",
        "#RandomForest class\n",
        "class RandomForest():\n",
        "    def __init__(self, min_samples, max_depth, nb_features):\n",
        "        self.root = None\n",
        "        self.min_samples = min_samples\n",
        "        self.max_depth = max_depth\n",
        "        self.pos = 0\n",
        "        self.nb_features = nb_features\n",
        "\n",
        "    #Return: Node\n",
        "    def build_tree(self, dataset, pos):\n",
        "\n",
        "        X = dataset[:, 1:]\n",
        "        Y = dataset[:, 0]\n",
        "\n",
        "        num_sample, num_feature = np.shape(X)\n",
        "\n",
        "        if num_sample > self.min_samples and pos < self.max_depth:\n",
        "            best_split = self.get_best_split(dataset, num_sample, num_feature)\n",
        "            if best_split[\"info_gain\"] > 0:\n",
        "                self.pos = self.pos + 1\n",
        "                left_subtree = self.build_tree(best_split[\"left_data\"], self.pos)\n",
        "                right_subtree= self.build_tree(best_split[\"right_data\"], self.pos)\n",
        "\n",
        "                return Node(index = best_split[\"index\"], threshold = best_split[\"threshold\"], left = left_subtree, right = right_subtree,info_gain = best_split[\"info_gain\"])\n",
        "\n",
        "        value = self.leaf_value(Y)\n",
        "        return Node(value = value)\n",
        "\n",
        "    #Return a dictionary\n",
        "    def get_best_split(self, dataset, num_sample, num_feature):\n",
        "\n",
        "        best_split = {}\n",
        "        max_info_gain = -999999999999\n",
        "        random_index = torch.randperm(num_feature)[:self.nb_features]\n",
        "        random_index = random_index + 1\n",
        "        for index in random_index:\n",
        "            threshold_values = dataset[:, index]\n",
        "            unique_values = np.unique(threshold_values)\n",
        "            for value in unique_values:\n",
        "                dataset_x, dataset_y = self.split(dataset, index, value)\n",
        "                if len(dataset_x) > 0 and len(dataset_y) > 0:\n",
        "                  info_gain = self.get_info_gain(dataset, dataset_x, dataset_y)\n",
        "                  if info_gain > max_info_gain:\n",
        "                      max_info_gain = info_gain\n",
        "                      best_split[\"index\"] = index\n",
        "                      best_split[\"threshold\"] = value\n",
        "                      best_split[\"left_data\"] = dataset_x\n",
        "                      best_split[\"right_data\"] = dataset_y\n",
        "                      best_split[\"info_gain\"] = info_gain\n",
        "        return best_split\n",
        "\n",
        "    def split(self, dataset, index, threshold):\n",
        "        dataset_x = np.array([row for row in dataset if row[index] <= threshold])\n",
        "        dataset_y = np.array([row for row in dataset if row[index] > threshold])\n",
        "        return dataset_x, dataset_y\n",
        "\n",
        "    def get_info_gain(self, dataset, dataset_x, dataset_y):\n",
        "        weight_x = len(dataset_x)/len(dataset)\n",
        "        weight_y = len(dataset_y)/len(dataset)\n",
        "        return self.gini_index(dataset) - weight_x*self.gini_index(dataset_x) - weight_y*self.gini_index(dataset_y)\n",
        "\n",
        "    def gini_index(self, dataset):\n",
        "        data_label = dataset[:, 0]\n",
        "        result = 0\n",
        "        labels = np.unique(data_label)\n",
        "        for label in labels:\n",
        "            value = len(data_label[data_label == label ])/len(data_label)\n",
        "            result += value**2\n",
        "\n",
        "        return 1 - result\n",
        "\n",
        "    def leaf_value(self, Y):\n",
        "        Y = list(Y)\n",
        "        return max(Y, key = Y.count)\n",
        "\n",
        "    def fit(self, dataset):\n",
        "        self.root = self.build_tree(dataset, self.pos)\n",
        "\n",
        "    def make_predictions(self, X):\n",
        "        return [self.predict(row) for row in X]\n",
        "\n",
        "    def predict(self, X):\n",
        "        cur_node = self.root\n",
        "        while cur_node.value is None:\n",
        "            if X[cur_node.index - 1] <= cur_node.threshold:\n",
        "                cur_node = cur_node.left\n",
        "            else:\n",
        "                cur_node = cur_node.right\n",
        "        return cur_node.value\n",
        "\n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "\n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "\n",
        "        else:\n",
        "            print(\"X_\"+str(tree.index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + indent)\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + indent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pviIt4SCp6IS"
      },
      "outputs": [],
      "source": [
        "#Boostraping Dataset\n",
        "def bootstrap_data(dataset):\n",
        "    num_sample, num_feature = np.shape(dataset)\n",
        "    row_index = []\n",
        "    for i in range (num_sample):\n",
        "        a = np.random.randint(num_sample)\n",
        "        row_index.append(a)\n",
        "    new_dataset = [dataset[index, :] for index in row_index]\n",
        "    new_dataset = np.stack(new_dataset)\n",
        "    return new_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySv85HwYp6IT",
        "outputId": "d1b5f697-ed0e-43b6-ef28-18f846d643e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "85\n"
          ]
        }
      ],
      "source": [
        "#Model Training\n",
        "rf_models = []\n",
        "accuracy = []\n",
        "for j in range(20):\n",
        "    min_e = np.random.randint(3, 13)\n",
        "    max_d = np.random.randint(5, 9)\n",
        "    nb_features = 5\n",
        "    model = RandomForest(min_e, max_d, nb_features)\n",
        "    new_data = bootstrap_data(dataset_train)\n",
        "    model.fit(new_data)\n",
        "    rf_models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Model Testing\n",
        "result = []\n",
        "count = 0\n",
        "X = dataset_test[:, 1:]\n",
        "Y = dataset_test[:, 0]\n",
        "for i in range(len(dataset_test)):\n",
        "    for nb in range(20):\n",
        "        result.append(rf_models[nb].predict(X[i]))\n",
        "    prediction = max(result, key=result.count)\n",
        "    if prediction == Y[i]:\n",
        "        count += 1\n",
        "print(int(count/len(dataset_test)*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
